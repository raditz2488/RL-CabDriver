{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state-action and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-c1ca6536adb3>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-c1ca6536adb3>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    update_output = # write here\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 1.0\n",
    "        self.learning_rate = 0.01     \n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = -0.0009\n",
    "        self.epsilon_min = 0.001\n",
    "        self.batch_size = 256        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        \n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        model = Sequential([\n",
    "            Dense(64, input_size=36, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(21)  \n",
    "        ])\n",
    "        \n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state_vector):\n",
    "        # Write your code here:\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after we generate each sample from the environment \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            # Choose a random action from amongst 21 possible actions\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state_vec = state_vector.reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state_vec)\n",
    "            return np.argmax(q_value[0])\n",
    "    \n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        # Write your code here:\n",
    "        # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = # write here\n",
    "            update_input = # write here\n",
    "            action, reward = [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                state_encod = env.state_encod_arch2(state,action)\n",
    "                           \n",
    "                \n",
    "                # Write your code from here\n",
    "                # 1. Predict the target from earlier model\n",
    "                \n",
    "                \n",
    "                # 2. Get the target for the Q-network\n",
    "                \n",
    "                \n",
    "                #3. Update your 'update_output' and 'update_input' batch. Be careful to use the encoded state-action pair\n",
    "\n",
    "                \n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    \n",
    "\n",
    "    #Call the DQN agent\n",
    "    \n",
    "    \n",
    "    while !terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randrange(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAeW0lEQVR4nO3deZhcdZ3v8fe3qnpJeg/dnU53ZyWBkI4EkhbCoiPIEriS6CgKiqhXwTsOc2HQOw883kcdfJx71RlFRxQYdWbcWMQtcqMMmyxigA4kgeydhCSdhKSzd9Lp9Pa9f9RJqDSddCWp7tN16vN6nnrqnN/5VdX39Ek+ffp3Tp1j7o6IiGS/WNgFiIhIZijQRUQiQoEuIhIRCnQRkYhQoIuIREQirA+urKz0CRMmhPXxIiJZadGiRTvcvaq/ZaEF+oQJE2hqagrr40VEspKZbTjWMg25iIhEhAJdRCQiFOgiIhGhQBcRiQgFuohIRAwY6Gb2YzPbbmavH2O5mdl3zazZzJaa2czMlykiIgNJZw/9P4A5x1l+FTAleNwM/ODUyxIRkRM1YKC7+7PAruN0mQf8xJMWAuVmNiZTBfbV9MYuvv7HleiyvyIiR8vEGHodsCllviVoexszu9nMmsysqbW19aQ+7PXNe/nBn9bS2nbopF4vIhJVQ3pQ1N3vd/dGd2+squr3m6sDOrOmFIAVb7ZlsjQRkayXiUDfDIxNma8P2gbF1JoSAFa9uW+wPkJEJCtlItDnAzcGZ7vMBva6+9YMvG+/KoryqSktZOVW7aGLiKQa8OJcZvYA8B6g0sxagC8DeQDufi+wALgaaAbagU8NVrGHnVlToiEXEZE+Bgx0d79+gOUO/G3GKkrD1DEl/GXtTrp6esmL67tRIiKQpd8UPaumlM6eXtbvOBB2KSIiw0ZWBvqZwYHRFVt1YFRE5LCsDPTTq4pJxIxVGkcXETkiKwM9PxFjcnUxKxXoIiJHZGWgQ3LYZaWGXEREjsjaQJ9aU8qWvR3sPdgVdikiIsNCFgf64W+MathFRASyOdDHJAN9pS4BICICZHGg15QWUjYijxW6BICICJDFgW5myQOj2kMXEQGyONABpo0pZeXWNnp6dbMLEZGsDvSG2lIOdvXoEgAiImR5oE+vKwNg2Za9IVciIhK+rA70ydXF5CdiLNuicXQRkawO9Lx4jKk1Jby+WXvoIiJZHegADbVlLNuyj+Rl2UVEclcEAr2UvQe7aNl9MOxSRERClfWB/taBUY2ji0huy/pAn1pTQjxmOtNFRHJe1gd6YV6cyVXFOjAqIjkv6wMdoKGuVEMuIpLzohHotWVsbzvE9raOsEsREQlNJAJ9em0poAOjIpLbIhHo0w4HusbRRSSHRSLQSwrzmFhZxGsKdBHJYZEIdICz68tY2qJAF5HcFZlAn1Ffzta9HWzbpwOjIpKbohPoY5PfGF2yaU/IlYiIhCMygd5QW0Y8ZixpUaCLSG6KTKAX5sWZWlOicXQRyVmRCXSAGWPLWbJpD726x6iI5KC0At3M5pjZKjNrNrM7+lk+zsyeNrNXzWypmV2d+VIHdk59Ofs6unljp+4xKiK5Z8BAN7M4cA9wFTANuN7MpvXp9r+Bh939XOA64PuZLjQdM8aWA2gcXURyUjp76OcBze6+zt07gQeBeX36OFAaTJcBWzJXYvomVxczMj/Okk0aRxeR3JNOoNcBm1LmW4K2VF8BbjCzFmAB8Hf9vZGZ3WxmTWbW1NraehLlHl88ZkyvK2OxTl0UkRyUqYOi1wP/4e71wNXAT83sbe/t7ve7e6O7N1ZVVWXoo492zthylm/dR2d376C8v4jIcJVOoG8GxqbM1wdtqT4NPAzg7n8BCoHKTBR4ombUl9PZ3cuqN9vC+HgRkdCkE+gvA1PMbKKZ5ZM86Dm/T5+NwHsBzOwskoGe+TGVNBz+xujiTbvD+HgRkdAMGOju3g3cAjwGrCB5NssyM7vLzOYG3T4P3GRmS4AHgE+6eygng9eVj6CqpIBXNmocXURySyKdTu6+gOTBztS2L6VMLwcuymxpJ8fMaBxfQdOGXWGXIiIypCL1TdHDZo2vYNOug2zXlRdFJIdENtABFm3QOLqI5I5IBnpDbRkFiZgCXURySiQDPT8RY0Z9OU0KdBHJIZEMdICZ4ytYtmUvHV09YZciIjIkIhvojeMr6OpxXR9dRHJGZAN9pg6MikiOiWygjyrKZ1JVEYt0PrqI5IjIBjrArHEVLNqwm5C+tCoiMqQiHeiNEyrY3d7Fuh26g5GIRF/EA30UAC+t17CLiERfpAN9UmURVSUFvLhuZ9iliIgMukgHuplx/sRRLFy3S+PoIhJ5kQ50gNmTTuPNfR1s3NUedikiIoMqJwIdYKGGXUQk4iIf6KdXFVFZXMDCdTowKiLRFvlANzPOnzSKF9ft1Di6iERa5AMdYPbEUWzZ28GmXQfDLkVEZNDkRqBrHF1EckBOBPrk6mJOK8pn4XoFuohEV04E+lvj6DowKiLRlROBDslhl817DrJxp85HF5FoyplAv2hyJQDPNbeGXImIyODImUCfVFlEbVkhz63eEXYpIiKDImcC3cy4eEolL6zdQU+vzkcXkejJmUAHuHhKFfs6ulnasifsUkREMi63An1yJWbw/BoNu4hI9ORUoI8qyqehtpTnmhXoIhI9ORXoABdPruLVjbvZf6g77FJERDIq5wL9XVMq6epx3cVIRCInrUA3szlmtsrMms3sjmP0+bCZLTezZWb2i8yWmTmzxldQkIjxnMbRRSRiEgN1MLM4cA9wOdACvGxm8919eUqfKcCdwEXuvtvMqger4FNVmBfnvImjeG6NvmAkItGSzh76eUCzu69z907gQWBenz43Afe4+24Ad9+e2TIz66/OqGJt6wE26bZ0IhIh6QR6HbApZb4laEt1BnCGmf3ZzBaa2Zz+3sjMbjazJjNram0Nbw/50qnJPyCeXjWsf++IiJyQTB0UTQBTgPcA1wP/ZmblfTu5+/3u3ujujVVVVRn66BM3qaqYCaeN5KmVCnQRiY50An0zMDZlvj5oS9UCzHf3LndfD6wmGfDD1iVTq/nL2p0c7OwJuxQRkYxIJ9BfBqaY2UQzyweuA+b36fNbknvnmFklySGYdRmsM+MunVrNoe5eXlirs11EJBoGDHR37wZuAR4DVgAPu/syM7vLzOYG3R4DdprZcuBp4H+5+7A+0fu8iaMoyo/zpIZdRCQiBjxtEcDdFwAL+rR9KWXagduDR1YoSMS5eEolT6/cjrtjZmGXJCJySnLum6KpLp1azda9Hax8sy3sUkRETllOB/olZyZPX9TZLiISBTkd6NWlhbyjrownV2wLuxQRkVOW04EOcMW00byycQ/b93WEXYqIyCnJ+UCfM70GgMeWay9dRLJbzgf65OpiJlUW8djrb4ZdiojIKcn5QDczrpxew8J1O9nT3hl2OSIiJy3nAx1gTkMN3b3Okyt0touIZC8FOnB2fRljygr54zINu4hI9lKgEwy7NNTw7OpWDuheoyKSpRTogSsbajjU3cszq3UnIxHJTgr0wDsnVDCqKJ8Fr20NuxQRkZOiQA8k4jGuml7DEyu2adhFRLKSAj3F3Bm1dHT18oQuBSAiWUiBnuKdE0YxpqyQ+Yu3hF2KiMgJU6CniMWM9509hmfXtOpLRiKSdRTofcydUUdXj/MHXQpARLKMAr2P6XWlTKws0rCLiGQdBXofZsY1M2pZuH4n23RJXRHJIgr0fsydMQZ3+P0S7aWLSPZQoPdjcnUJZ9eX8ciiFpL3vxYRGf4U6Mdw7ax6Vr7ZxrIt+8IuRUQkLQr0Y5g7o478RIxfNm0KuxQRkbQo0I+hbGQeV0wbze+WbOFQd0/Y5YiIDEiBfhzXNo5lT3uXbnwhIllBgX4cF0+upKa0UMMuIpIVFOjHEY8Zfz2zjmdWt+qcdBEZ9hToA7i2cSy9jvbSRWTYU6APYGJlERdPruQXL26kp1fnpIvI8KVAT8MNs8exZW8HT63UwVERGb4U6Gm47KzRjC4t4GcLN4RdiojIMaUV6GY2x8xWmVmzmd1xnH4fNDM3s8bMlRi+RDzG9eeN45nVrWzYeSDsckRE+jVgoJtZHLgHuAqYBlxvZtP66VcC3Aq8mOkih4Pr3jmOeMz4xYsbwy5FRKRf6eyhnwc0u/s6d+8EHgTm9dPvq8DXgUie31dTVsjlZ43m4aZNdHTpm6MiMvykE+h1QOo5ey1B2xFmNhMY6+7/73hvZGY3m1mTmTW1traecLFhu/GC8exu79LNL0RkWDrlg6JmFgO+BXx+oL7ufr+7N7p7Y1VV1al+9JC74PTTmFpTwg+fX6fL6orIsJNOoG8GxqbM1wdth5UA04E/mdkbwGxgftQOjELybkY3vWsSq7ft55nV2fcXhohEWzqB/jIwxcwmmlk+cB0w//BCd9/r7pXuPsHdJwALgbnu3jQoFYfsmhm1VJcU8KPn14ddiojIUQYMdHfvBm4BHgNWAA+7+zIzu8vM5g52gcNNfiLGJy6cwHNrdrBiq25+ISLDR1pj6O6+wN3PcPfT3f1rQduX3H1+P33fE9W988M+dv44RuTF+eFz2ksXkeFD3xQ9CeUj8/lwYz3zl2xm696DYZcjIgIo0E/aZ941CXe475l1YZciIgIo0E/a2FEj+cC5dTzw0ka2t0Xyu1QikmUU6Kfgby+ZTFdPr8bSRWRYUKCfggmVRcydUcvPFm5g14HOsMsRkRynQD9Ft1w6mYNdPfzoeY2li0i4FOinaHJ1CVdPH8N/vqC9dBEJlwI9A267bArtnd18/+nmsEsRkRymQM+AKaNL+ODMen6ycAOb9+i8dBEJhwI9Q267/AwA7n58dciViEiuUqBnSF35CG6cPZ5fvdLCmm1tYZcjIjlIgZ5Bn7tkMiPzE3zjsVVhlyIiOUiBnkGjivL57Lsn8fjybbywdkfY5YhIjlGgZ9hN755EXfkI7vr9crp7esMuR0RyiAI9wwrz4nzxv53FyjfbeOCljWGXIyI5RIE+CK6aXsPsSaP4l8dXs6ddXzYSkaGhQB8EZsaXr2lg38EuvqXTGEVkiCjQB8lZY0q5YfZ4frZwA0tb9oRdjojkAAX6IPrClWdSWVzAHb96jS4dIBWRQaZAH0SlhXncNa+B5Vv38aPndc10ERlcCvRBdmVDDZdPG83dT6xmw84DYZcjIhGmQB9kZsZX500nEYvxxd+8jruHXZKIRJQCfQjUlBVyx1VTeb55Bz9buCHsckQkohToQ+Rj54/j3WdU8bUFK1jbuj/sckQkghToQ8TM+OaHzqYwL87tDy3WWS8iknEK9CE0urSQf/rAO1jSspd/fUp3NxKRzFKgD7Gr3zGGvz63ju89tYaF63aGXY6IRIgCPQR3vX86E04r4u8eeJXtbR1hlyMiEaFAD0FxQYLv3zCTto4ubn1gMT29OpVRRE6dAj0kU2tK+eq86fxl3U7ufkIX8BKRU5dWoJvZHDNbZWbNZnZHP8tvN7PlZrbUzJ40s/GZLzV6rm0cy4cb6/nXp5r54+tvhl2OiGS5AQPdzOLAPcBVwDTgejOb1qfbq0Cju58NPAJ8I9OFRtVd86Zzzthy/v6hxby+eW/Y5YhIFktnD/08oNnd17l7J/AgMC+1g7s/7e7twexCoD6zZUZXYV6c+2+cRfnIPG76SZMOkorISUsn0OuATSnzLUHbsXwa+EN/C8zsZjNrMrOm1tbW9KuMuOqSQv7txkb2tHdx808W0dHVE3ZJIpKFMnpQ1MxuABqBb/a33N3vd/dGd2+sqqrK5Ednvel1ZXz7I+ewpGUPt/ziVd1gWkROWDqBvhkYmzJfH7QdxcwuA74IzHX3Q5kpL7fMmV7DXXMbeGLFNu789Wu6MqOInJBEGn1eBqaY2USSQX4d8NHUDmZ2LnAfMMfdt2e8yhzy8QsmsGN/J995cg2jivK58+qzwi5JRLLEgIHu7t1mdgvwGBAHfuzuy8zsLqDJ3eeTHGIpBn5pZgAb3X3uINYdabddNoXd7Z3c9+w6SgoT3HLplLBLEpEskM4eOu6+AFjQp+1LKdOXZbiunGZmfOWaBvYf6uaf/2s1vQ7/870KdRE5vrQCXYZeLGZ880MzMIxvPb6aXnduu+yMsMsSkWFMgT6MxWPGNz50NjGDu59YQ1dPL1+44kyCYS0RkaMo0Ie5eMz4+gfPJhGPcc/Ta9nR1snXPjCdRFyX4RGRoynQs0AsZvzTB6ZTVZzPd59qZsf+Q3zvozMZkR8PuzQRGUa0m5clzIzbrziTr75/Ok+t2s5Hf7iQ1jad7i8ib1GgZ5mPzx7PDz42ixVb9zH3e8+ztGVP2CWJyDChQM9Cc6bX8Ku/uZCYGdfe+xd+++rbvrgrIjlIgZ6lGmrLmH/LRcwYW85tDy3mH3+/jEPduqiXSC5ToGex04oL+PlnzueTF07g3//8Bh/8wQus33Eg7LJEJCQK9CyXF4/xlbkN3P/xWbTsPsj7vvscv36lRRf2EslBCvSIuKKhhj/c+i4a6sq4/eEl/I+fLWL7Pt0sQySXKNAjZEzZCB64aTZ3XjWVp1e1cvm3n+VXi7S3LpIrFOgRE48Zn/2r0/nDre9iSnUxn//lEm788Uusbd0fdmkiMsgU6BF1elUxD332Ar58zTQWb9zDnLuf5f8sWEFbR1fYpYnIIFGgR1g8Znzqook89YX38P5z6rjv2XVc+i/P8HDTJt3iTiSCFOg5oKqkgG9eO4PffO5CastH8A+PLOXKu59lwWtb6e3V+LpIVCjQc8i54yr47ecu5N4bZhEz43M/f4W59zzPkyu2KdhFIsDCOgOisbHRm5qaQvlsgZ5e53eLN/PtJ1azaddBzhhdzM3vPp25M2rJT+j3vMhwZWaL3L2x32UK9NzW1dPLo0u3cN8z61j5Zhtjygr51EUTuHbWWCqK8sMuT0T6UKDLgNydP61u5d4/reXF9bvIT8R439lj+Nj545k5rlx3SRIZJo4X6LrBhQDJ661fcmY1l5xZzYqt+/j5ixv4zSub+fUrmzlrTCkfnFnH3Bm1VJcWhl2qiByD9tDlmPYf6mb+4i088NJGXtu8l5jBhadX8v5z67iyYTQlhXlhlyiSczTkIqeseft+frd4M79dvJlNuw6Sn4hx0emncfm0Gi6bVk11ifbcRYaCAl0yxt15ZeMeFry2lceXb2PjrnYAzh1XzmVnjebiyZVMrysjHtOYu8hgUKDLoHB3Vm1r4/Fl23h8xTaWtuwFoLQwwYWnV3LRlEounlzJhNNG6qCqSIYo0GVItLYd4oW1O/hz8w6eX7ODLXuTl++tLC5g5rhyZo2vYNb4CqbXlVGYFw+5WpHspLNcZEhUlRQw75w65p1Th7vzxs52Xli7g0UbdvPKht381/JtAOTFjWm1ZTTUljJtTCkNtaVMrSllRL5CXuRUaA9dhsyO/Yd4deMeFm3YzeJNu1m+ZR/7OroBiBlMrCzirDGlnDG6hNOriplUVcTEyiLtzYuk0B66DAuVxQVcPm00l08bDSTH4DfvOciyLftYvmUfy7fu49WNe3h06dYjrzGD+ooRTKpMBvy4USOprxjJ2FEjqCsfoVMnRVIo0CU0ZkZ9RTKgr2yoOdLe3tnN+h0HWNt6gHWt+1nbeoC12/fz0vpdHOzqOeo9ykfmUV8xgvrykdSWj6C6tIDqkgJGlxZSXVJAdUkhpSMSOigrOUGBLsPOyPwEDbVlNNSWHdXu7uw80EnL7oO07G4/6rm5dT/PrmmlvbPnbe9XkIhRFYT8qKJ8KkbmUVGUT8XI5HT5yOT0qKLkdPmIPBJxXaBMsk9agW5mc4DvAHHgh+7+f/ssLwB+AswCdgIfcfc3Mluq5Dozo7K4gMriAs4ZW95vn/2Hutm+r4Nt+w6xva2D1rZDbG87dKRt0652lmzqZE97F53HucnHyPw4xQUJigsTlBQkKCnMOzJfXJCgJHguLkxQlJ+gMC9OYV6MEXlxRuTHKcyLMyIveM6PU5iI6ZeEDLoBA93M4sA9wOVAC/Cymc139+Up3T4N7Hb3yWZ2HfB14CODUbDI8RQXJCiuKmZSVfFx+7k77Z097G5Phvvu9k52t3ex+0Anu9s72d/Rzf5D3bQd6j4y3dp2iLaOrmTboW5O9HyCvLgFwZ8M+/xEjLx4jPy4JZ+D+eS0kR9M5yViwbQd3SceIx6ztz0SqfP29uXJPjHiMYjHYv33McOM4GHEDIzgOVgWM8MInmO8NR0sI5iPpb6Hhr4GVTp76OcBze6+DsDMHgTmAamBPg/4SjD9CPA9MzPX7eZlmDIzigoSFBUkqK848dcf/oXQ1tFNe2c3B7t66OjqpaOrh4OdPXR0B89B+8GunuSjs4dDwbKuHudQdy9dPW89DnT20Jna1t1LZ4/T2Z3s39XTS3eW34yk7y8DjKN+YRxuO9L/yOvsyOv7bU95/9Qeb++f+t7Hf0/6vOatfgO/rk8ZR/W59b1TuGZGLZmWTqDXAZtS5luA84/Vx927zWwvcBqwI7WTmd0M3Awwbty4kyxZJHypvxCGWm+v0xkEfm8vdPf20uNOT6/T3eP0utPd6/T2Jp97Dj/S7pN83153nOQvL3fodXA8+Xyk7ejnt5Yn2w7Xm/paPPl8+P17ky888h49KfuBfXcJD+8jep/lHrS8Nd/39d5nPv3XHl7O25b3X8vx+hyeKBsxOGdnDem/Rne/H7gfkuehD+Vni0RFLGYUxuI6P1/eJp2jNJuBsSnz9UFbv33MLAGUkTw4KiIiQySdQH8ZmGJmE80sH7gOmN+nz3zgE8H0h4CnNH4uIjK0BhxyCcbEbwEeI3na4o/dfZmZ3QU0uft84EfAT82sGdhFMvRFRGQIpTWG7u4LgAV92r6UMt0BXJvZ0kRE5ETomw4iIhGhQBcRiQgFuohIRCjQRUQiIrQbXJhZK7DhJF9eSZ9voeYArXNu0DrnhlNZ5/HuXtXfgtAC/VSYWdOx7tgRVVrn3KB1zg2Dtc4achERiQgFuohIRGRroN8fdgEh0DrnBq1zbhiUdc7KMXQREXm7bN1DFxGRPhToIiIRkXWBbmZzzGyVmTWb2R1h13OyzGysmT1tZsvNbJmZ3Rq0jzKzx81sTfBcEbSbmX03WO+lZjYz5b0+EfRfY2afONZnDhdmFjezV83s0WB+opm9GKzbQ8FlmjGzgmC+OVg+IeU97gzaV5nZleGsSXrMrNzMHjGzlWa2wswuiPp2NrO/D/5dv25mD5hZYdS2s5n92My2m9nrKW0Z265mNsvMXgte812zNG7ImryVVHY8SF6+dy0wCcgHlgDTwq7rJNdlDDAzmC4BVgPTgG8AdwTtdwBfD6avBv5A8taEs4EXg/ZRwLrguSKYrgh7/QZY99uBXwCPBvMPA9cF0/cCfxNMfw64N5i+DngomJ4WbPsCYGLwbyIe9nodZ33/E/hMMJ0PlEd5O5O8JeV6YETK9v1k1LYz8G5gJvB6SlvGtivwUtDXgtdeNWBNYf9QTvAHeAHwWMr8ncCdYdeVoXX7HXA5sAoYE7SNAVYF0/cB16f0XxUsvx64L6X9qH7D7UHyjldPApcCjwb/WHcAib7bmOQ1+C8IphNBP+u73VP7DbcHybt3rSc4AaHv9oviduatewyPCrbbo8CVUdzOwIQ+gZ6R7RosW5nSflS/Yz2ybcilvxtW14VUS8YEf2KeC7wIjHb3rcGiN4HRwfSx1j3bfiZ3A/8A9AbzpwF73L07mE+t/6ibjwOHbz6eTes8EWgF/j0YZvqhmRUR4e3s7puBfwY2AltJbrdFRHs7H5ap7VoXTPdtP65sC/TIMbNi4FfAbe6+L3WZJ381R+a8UjN7H7Dd3ReFXcsQSpD8s/wH7n4ucIDkn+JHRHA7VwDzSP4yqwWKgDmhFhWCMLZrtgV6OjeszhpmlkcyzH/u7r8OmreZ2Zhg+Rhge9B+rHXPpp/JRcBcM3sDeJDksMt3gHJL3lwcjq7/WDcfz6Z1bgFa3P3FYP4RkgEf5e18GbDe3VvdvQv4NcltH+XtfFimtuvmYLpv+3FlW6Cnc8PqrBAcsf4RsMLdv5WyKPWG258gObZ+uP3G4Gj5bGBv8KfdY8AVZlYR7BldEbQNO+5+p7vXu/sEktvuKXf/GPA0yZuLw9vXub+bj88HrgvOjpgITCF5AGnYcfc3gU1mdmbQ9F5gORHeziSHWmab2cjg3/nhdY7sdk6Rke0aLNtnZrODn+GNKe91bGEfVDiJgxBXkzwjZC3wxbDrOYX1uJjkn2NLgcXB42qSY4dPAmuAJ4BRQX8D7gnW+zWgMeW9/jvQHDw+Ffa6pbn+7+Gts1wmkfyP2gz8EigI2guD+eZg+aSU138x+FmsIo2j/yGv6zlAU7Ctf0vybIZIb2fgH4GVwOvAT0meqRKp7Qw8QPIYQRfJv8Q+ncntCjQGP7+1wPfoc2C9v4e++i8iEhHZNuQiIiLHoEAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiETE/wcIvTxPyNKaOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
